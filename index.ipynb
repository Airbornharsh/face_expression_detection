{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 07:32:19.722658: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-18 07:32:19.999440: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-18 07:32:20.000469: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 07:32:20.924461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_Folder = 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dirs = os.listdir(image_Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(list_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(dir):\n",
    "    if dir == \"angry\":\n",
    "        return 0\n",
    "    elif dir == \"disgust\":\n",
    "        return 1\n",
    "    elif dir == \"fear\":\n",
    "        return 2\n",
    "    elif dir == \"happy\":\n",
    "        return 3\n",
    "    elif dir == \"neutral\":\n",
    "        return 4\n",
    "    elif dir == \"sad\":\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def get_emotion(index):\n",
    "    if index == 0:\n",
    "        return \"angry\"\n",
    "    elif index == 1:\n",
    "        return \"disgust\"\n",
    "    elif index == 2:\n",
    "        return \"fear\"\n",
    "    elif index == 3:\n",
    "        return \"happy\"\n",
    "    elif index == 4:\n",
    "        return \"neutral\"\n",
    "    elif index == 5:\n",
    "        return \"sad\"\n",
    "    else:\n",
    "        return \"surprise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for dir in list_dirs:\n",
    "    list_images = os.listdir(image_Folder + dir)\n",
    "    for image in list_images:\n",
    "        img = np.asarray(Image.open(image_Folder + dir + \"/\" + image)) \n",
    "        img = img.reshape(48, 48, 1) / 255.0\n",
    "        imgs.append(img)\n",
    "        labels.append(get_index(dir))\n",
    "    del(list_images)\n",
    "    del(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25596\n",
      "25596\n"
     ]
    }
   ],
   "source": [
    "print(len(imgs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.asarray(imgs)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(imgs, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20476, 48, 48, 1)\n",
      "(20476,)\n",
      "(5120, 48, 48, 1)\n",
      "(5120,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "# # mobilenet_model = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\"\n",
    "\n",
    "# pretrained_model = hub.KerasLayer(mobilenet_model,input_shape=(224,224,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 46, 46, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 23, 23, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 23, 23, 8)         0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 20, 20, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 10, 10, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 10, 10, 32)        0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 64)                204864    \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 252,215\n",
      "Trainable params: 252,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.applications.vgg16(input_shape=(224,224,1)),\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(7)\n",
    "# ])\n",
    "\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, Concatenate\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# img_size_target = 224\n",
    "# img_input = Input(shape=(img_size_target, img_size_target, 1))\n",
    "# img_conc = Concatenate()([img_input, img_input, img_input])  \n",
    "# model = VGG16(input_tensor=img_conc)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(224,224)),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(128,activation='relu'),\n",
    "#     tf.keras.layers.Dense(256,activation='relu'),\n",
    "#     tf.keras.layers.Dense(128,activation='relu'),\n",
    "#     tf.keras.layers.Dense(64,activation='relu'),\n",
    "#     tf.keras.layers.Dense(7,activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "num_of_classes = 7\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(8, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(4,4), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(num_of_classes, activation='sigmoid'))\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     pretrained_model,\n",
    "#     tf.keras.layers.Dense(7)\n",
    "# ])\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "640/640 [==============================] - 7s 9ms/step - loss: 1.8254 - accuracy: 0.2122\n",
      "Epoch 2/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.6937 - accuracy: 0.3106\n",
      "Epoch 3/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.5870 - accuracy: 0.3727\n",
      "Epoch 4/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.5313 - accuracy: 0.3989\n",
      "Epoch 5/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.4821 - accuracy: 0.4181\n",
      "Epoch 6/50\n",
      "640/640 [==============================] - 6s 10ms/step - loss: 1.4537 - accuracy: 0.4304\n",
      "Epoch 7/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.4241 - accuracy: 0.4459\n",
      "Epoch 8/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.4000 - accuracy: 0.4561\n",
      "Epoch 9/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.3755 - accuracy: 0.4682\n",
      "Epoch 10/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.3533 - accuracy: 0.4782\n",
      "Epoch 11/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.3376 - accuracy: 0.4870\n",
      "Epoch 12/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.3276 - accuracy: 0.4903\n",
      "Epoch 13/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.3094 - accuracy: 0.4982\n",
      "Epoch 14/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2963 - accuracy: 0.5048\n",
      "Epoch 15/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2846 - accuracy: 0.5050\n",
      "Epoch 16/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2640 - accuracy: 0.5208\n",
      "Epoch 17/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2581 - accuracy: 0.5155\n",
      "Epoch 18/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2478 - accuracy: 0.5232\n",
      "Epoch 19/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2421 - accuracy: 0.5232\n",
      "Epoch 20/50\n",
      "640/640 [==============================] - 8s 12ms/step - loss: 1.2209 - accuracy: 0.5351\n",
      "Epoch 21/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.2221 - accuracy: 0.5309\n",
      "Epoch 22/50\n",
      "640/640 [==============================] - 8s 12ms/step - loss: 1.2051 - accuracy: 0.5371\n",
      "Epoch 23/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1985 - accuracy: 0.5454\n",
      "Epoch 24/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1904 - accuracy: 0.5487\n",
      "Epoch 25/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1771 - accuracy: 0.5533\n",
      "Epoch 26/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1737 - accuracy: 0.5524\n",
      "Epoch 27/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1657 - accuracy: 0.5570\n",
      "Epoch 28/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1480 - accuracy: 0.5632\n",
      "Epoch 29/50\n",
      "640/640 [==============================] - 6s 10ms/step - loss: 1.1456 - accuracy: 0.5627\n",
      "Epoch 30/50\n",
      "640/640 [==============================] - 7s 10ms/step - loss: 1.1397 - accuracy: 0.5728\n",
      "Epoch 31/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1393 - accuracy: 0.5706\n",
      "Epoch 32/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1303 - accuracy: 0.5704\n",
      "Epoch 33/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1238 - accuracy: 0.5734\n",
      "Epoch 34/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1279 - accuracy: 0.5755\n",
      "Epoch 35/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.1107 - accuracy: 0.5798\n",
      "Epoch 36/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0985 - accuracy: 0.5888\n",
      "Epoch 37/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0964 - accuracy: 0.5847\n",
      "Epoch 38/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0884 - accuracy: 0.5926\n",
      "Epoch 39/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0895 - accuracy: 0.5857\n",
      "Epoch 40/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0814 - accuracy: 0.5950\n",
      "Epoch 41/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0706 - accuracy: 0.5930\n",
      "Epoch 42/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0724 - accuracy: 0.5967\n",
      "Epoch 43/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0720 - accuracy: 0.5957\n",
      "Epoch 44/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0580 - accuracy: 0.5989\n",
      "Epoch 45/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0626 - accuracy: 0.5995\n",
      "Epoch 46/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0545 - accuracy: 0.6071\n",
      "Epoch 47/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0454 - accuracy: 0.6075\n",
      "Epoch 48/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0533 - accuracy: 0.6067\n",
      "Epoch 49/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0419 - accuracy: 0.6113\n",
      "Epoch 50/50\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 1.0408 - accuracy: 0.6104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8fb3af410>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 3ms/step - loss: 1.3558 - accuracy: 0.4887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.355818510055542, 0.4886718690395355]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"face_expression-v2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
